{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyabf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 1. Load the ABF file\n",
    "# ---------------------------\n",
    "# Replace \"file.abf\" with the path to your ABF file\n",
    "abf = pyabf.ABF(\"/Path/to/Abf/file/file.abf\")\n",
    "\n",
    "abf.setSweep(1)\n",
    "signal = abf.sweepY   # Ionic current (e.g., in pA)\n",
    "time = abf.sweepX   # Time vector (e.g., in seconds)\n",
    "\n",
    "#signal_data = abf.data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sampling Rate:\", abf.dataRate, \"Hz\")\n",
    "\n",
    "print(\"Number of Sweeps:\", abf.sweepCount)\n",
    "\n",
    "print(\"Protocol Name:\", abf.protocol)\n",
    "\n",
    "print(\"Recording Start Time:\", abf.abfDateTime)\n",
    "\n",
    "print(\"Channel Units:\", abf.adcUnits)\n",
    "\n",
    "print(\"Channel Scaling Factors:\", abf.adcUnits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyabf.tools.abfHeaderDisplay import abfInfoPage\n",
    "\n",
    "info_page = abfInfoPage(abf)\n",
    "header_text = info_page.getText()  \n",
    "print(header_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 2. Plot the ionic current trace for single sweep\n",
    "# ---------------------------\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(time, signal, label=\"Ionic current\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Current (pA)\")\n",
    "plt.title(\"Ionic Current Trace\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Sweep Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sweeps = []\n",
    "all_times = []\n",
    "for sweep in range(346):\n",
    "    abf.setSweep(sweep)\n",
    "    all_sweeps.append(abf.sweepY)\n",
    "    all_times.append(abf.sweepX)\n",
    "\n",
    "data = np.concatenate(all_sweeps)\n",
    "time = np.concatenate(all_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.reshape(-1, 1)\n",
    "print(\"Length of data\", len(data))\n",
    "n_clusters = 2\n",
    "\n",
    "# Apply k-means clustering\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "kmeans.fit(data2)\n",
    "\n",
    "# Get cluster labels\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Get the cluster centroids\n",
    "centroids = kmeans.cluster_centers_\n",
    "print(centroids)\n",
    "\n",
    "# Get points in each cluster\n",
    "cluster_1 = data2[labels == 0]\n",
    "cluster_2 = data2[labels == 1]\n",
    "# plot_cluster_histogram(cluster_1, cluster_2)\n",
    "cluster1_indices = np.where(kmeans.labels_ == 0)[0]\n",
    "cluster2_indices = np.where(kmeans.labels_ == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_1_flat = np.array([val[0] for val in cluster_1])\n",
    "cluster_2_flat = np.array([val[0] for val in cluster_2])\n",
    "plt.figure()\n",
    "plt.hist(cluster_1_flat, bins=100, color='blue', alpha=0.7, label='Cluster 1')\n",
    "plt.hist(cluster_2_flat, bins=100, color='red', alpha=0.7, label='Cluster 2')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Cluster 1 and Cluster 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis based on threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 3. Define threshold and event detection parameters\n",
    "# -------------------------------\n",
    "threshold = 180\n",
    "\n",
    "sample_rate = abf.dataRate\n",
    "\n",
    "min_event_duration = 0.0001  \n",
    "min_event_points = int(min_event_duration * sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect indices where current is below threshold\n",
    "below_threshold = np.where(data < threshold)[0]\n",
    "if len(below_threshold) == 0:\n",
    "    print(\"No events detected with the current threshold.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 4. Cluster contiguous indices into individual events\n",
    "# -------------------------------\n",
    "def cluster_indices(indices, max_gap=5):\n",
    "    \"\"\"\n",
    "    Cluster indices into groups if consecutive indices are separated\n",
    "    by no more than max_gap samples.\n",
    "    \"\"\"\n",
    "    if len(indices) == 0:\n",
    "        return []\n",
    "    \n",
    "    clusters = []\n",
    "    current_cluster = [indices[0]]\n",
    "    \n",
    "    for i in range(1, len(indices)):\n",
    "        if indices[i] - indices[i-1] <= max_gap:\n",
    "            current_cluster.append(indices[i])\n",
    "        else:\n",
    "            clusters.append(current_cluster)\n",
    "            current_cluster = [indices[i]]\n",
    "    clusters.append(current_cluster)\n",
    "    return clusters\n",
    "\n",
    "clusters = cluster_indices(below_threshold)\n",
    "\n",
    "\n",
    "events = [cluster for cluster in clusters if len(cluster) >= min_event_points]\n",
    "\n",
    "print(f\"Detected {len(events)} events.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------- \n",
    "# 5. Group contiguous indices into single events\n",
    "# ------------------------------- \n",
    "\n",
    "def group_contiguous(indices, max_gap=1):\n",
    "    groups = []\n",
    "    current_group = [indices[0]]\n",
    "    \n",
    "    for i in indices[1:]:\n",
    "        if i - current_group[-1] <= max_gap:\n",
    "            current_group.append(i)\n",
    "        else:\n",
    "            groups.append(current_group)\n",
    "            current_group = [i]\n",
    "    groups.append(current_group)\n",
    "    return groups\n",
    "\n",
    "clusters = group_contiguous(below_threshold)\n",
    "\n",
    "\n",
    "event_groups = [cluster for cluster in clusters if len(cluster) >= min_event_points]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 6. Extract event properties\n",
    "# ---------------------------\n",
    "events = []\n",
    "for group in event_groups:\n",
    "    start_idx = group[0]\n",
    "    end_idx = group[-1]\n",
    "    event_time = time[start_idx:end_idx+1]\n",
    "    event_data = data[start_idx:end_idx+1]\n",
    "    \n",
    "    duration = event_time[-1] - event_time[0]\n",
    "    amplitude = np.min(event_data)  \n",
    "    \n",
    "    events.append({\n",
    "        \"start_time\": event_time[0],\n",
    "        \"end_time\": event_time[-1],\n",
    "        \"duration\": duration,\n",
    "        \"amplitude\": amplitude\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 7. Report the detected events\n",
    "# ---------------------------\n",
    "print(\"Detected events:\")\n",
    "for i, event in enumerate(events, start=1):\n",
    "    print(f\"Event {i}: Start = {event['start_time']:.3f} s, \"\n",
    "          f\"End = {event['end_time']:.3f} s, Duration = {event['duration']:.3f} s, \"\n",
    "          f\"Amplitude = {event['amplitude']:.2f} pA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ---------------------------##\n",
    "## ONLY VALID FOR SINGLE SWEEP ##\n",
    "## ---------------------------##\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Plot the full trace\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time, signal, color=\"lightgray\", label=\"Full Trace\")\n",
    "\n",
    "# Use a colormap to assign different colors to each event\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(event_groups)))\n",
    "\n",
    "# Highlight each event over the full trace\n",
    "for i, group in enumerate(event_groups):\n",
    "    plt.plot(time[group], data[group], color=colors[i],\n",
    "             linewidth=2, label=f\"Event {i+1}\")\n",
    "\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Current (pA)\")\n",
    "plt.title(\"Ionic Current Trace with Highlighted Events\")\n",
    "#plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a list to store event information as dictionaries\n",
    "event_list = []\n",
    "for i, group in enumerate(event_groups, start=1):\n",
    "    # Get the indices for this event\n",
    "    extra_points = 200\n",
    "    start_idx = group[0] - extra_points\n",
    "    end_idx = group[-1] + extra_points\n",
    "    \n",
    "    # Extract the time and current for this event and convert to lists\n",
    "    event_time = time[start_idx:end_idx+1].tolist()\n",
    "    event_current = data[start_idx:end_idx+1].tolist()\n",
    "    \n",
    "    ## little extra points\n",
    "    extra_point = 10\n",
    "    start_idx = group[0] - extra_point\n",
    "    end_idx = group[-1] + extra_point\n",
    "    \n",
    "    # Extract the time and current for this event and convert to lists\n",
    "    event_time_l = time[start_idx:end_idx+1].tolist()\n",
    "    event_current_l = data[start_idx:end_idx+1].tolist()\n",
    "\n",
    "\n",
    "    # Calculate duration and amplitude (minimum current)\n",
    "    duration = event_time_l[-1] - event_time_l[0]\n",
    "    amplitude = min(event_current_l)\n",
    "    \n",
    "    # Append the event details to the list\n",
    "    event_list.append({\n",
    "        \"event_index\": i,\n",
    "        \"start_time\": event_time[0],\n",
    "        \"end_time\": event_time[-1],\n",
    "        \"duration\": duration,\n",
    "        \"amplitude\": amplitude,\n",
    "        \"time_series\": event_time,\n",
    "        \"current_series\": event_current,\n",
    "        \"exact_time_series\": event_time_l,\n",
    "        \"exact_current_series\": event_current_l\n",
    "    })\n",
    "\n",
    "# Convert the list of dictionaries into a pandas DataFrame\n",
    "df_events = pd.DataFrame(event_list)\n",
    "\n",
    "# (Optional) Save the DataFrame to a CSV file\n",
    "#df_events.to_csv(\"detected_events.csv\", index=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_events = pd.read_csv(\"detected_events.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "\n",
    "def plot_event(event_idx, events_df):\n",
    "    \"\"\"\n",
    "    Plot an individual event from events_df using its time_series and current_series,\n",
    "    and mark the event's start and end times with vertical lines.\n",
    "    \n",
    "    Parameters:\n",
    "      event_idx (int): The event index as stored in the \"event_index\" column.\n",
    "      events_df (pd.DataFrame): DataFrame containing event data with columns:\n",
    "                                'event_index', 'start_time', 'end_time',\n",
    "                                'time_series', and 'current_series'.\n",
    "    \"\"\"\n",
    "    # Retrieve the event row from events_df\n",
    "    event_row = events_df[events_df[\"event_index\"] == event_idx]\n",
    "    if event_row.empty:\n",
    "        print(f\"Event index {event_idx} not found in events_df.\")\n",
    "        return\n",
    "    \n",
    "    event_row = event_row.iloc[0]\n",
    "    time_series = event_row[\"time_series\"]        \n",
    "    current_series = event_row[\"current_series\"]     \n",
    "    start_time = event_row[\"start_time\"]\n",
    "    end_time = event_row[\"end_time\"]\n",
    "\n",
    "    # Convert string representations to lists if needed\n",
    "    if isinstance(time_series, str):\n",
    "        time_series = ast.literal_eval(time_series)\n",
    "    if isinstance(current_series, str):\n",
    "        current_series = ast.literal_eval(current_series)\n",
    "    \n",
    "    # Plot the event's current vs. time\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(time_series, current_series, label=f\"Event {event_idx}\", color=\"blue\")\n",
    "    \n",
    "    # Mark the event boundaries with vertical lines:\n",
    "    #plt.axvline(x=start_time, color=\"red\", linestyle=\"--\", linewidth=2, label=\"Start Time\")\n",
    "    #plt.axvline(x=end_time, color=\"green\", linestyle=\"-.\", linewidth=2, label=\"End Time\")\n",
    "    \n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Current (A)\")\n",
    "    plt.title(f\"Event {event_idx} (Time {start_time} to {end_time})\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# plot_event(event_idx=150, events_df=df_events)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_event(event_idx=150, events_df=df_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Let's assume `event_list` already exists and has the keys:\n",
    "# \"event_index\", \"start_time\", \"end_time\", \"duration\", \"amplitude\",\n",
    "# \"time_series\", and \"current_series\".\n",
    "\n",
    "for event in event_list:\n",
    "    # Convert the time and current lists to numpy arrays for easier computation.\n",
    "    event_time = np.array(event[\"time_series\"])\n",
    "    event_current = np.array(event[\"current_series\"])\n",
    "    \n",
    "    # Compute additional features if data exists.\n",
    "    if len(event_current) > 0:\n",
    "        baseline = event_current[0]\n",
    "        mean_current = np.mean(event_current)\n",
    "        std_current = np.std(event_current)\n",
    "        area = np.trapz(event_current, event_time)\n",
    "        peak_current = np.max(event_current)\n",
    "    else:\n",
    "        baseline = np.nan\n",
    "        mean_current = np.nan\n",
    "        std_current = np.nan\n",
    "        area = np.nan\n",
    "        peak_current = np.nan\n",
    "    \n",
    "    # Compute the gradient (slope) only if there are at least two points.\n",
    "    if len(event_current) > 1:\n",
    "        slopes = np.gradient(event_current, event_time)\n",
    "        max_slope = np.max(slopes)\n",
    "        min_slope = np.min(slopes)\n",
    "    else:\n",
    "        max_slope = np.nan\n",
    "        min_slope = np.nan\n",
    "    \n",
    "    n_points = len(event_current)\n",
    "    \n",
    "    # Save the features into the event dictionary.\n",
    "    event[\"baseline\"] = baseline\n",
    "    event[\"mean_current\"] = mean_current\n",
    "    event[\"std_current\"] = std_current\n",
    "    event[\"area\"] = area\n",
    "    event[\"peak_current\"] = peak_current\n",
    "    event[\"max_slope\"] = max_slope\n",
    "    event[\"min_slope\"] = min_slope\n",
    "    event[\"n_points\"] = n_points\n",
    "\n",
    "# Convert the updated list of dictionaries into a pandas DataFrame.\n",
    "df_events = pd.DataFrame(event_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Create an interactive histogram of the 'area' feature\n",
    "fig = px.histogram(df_events, x=\"rms_noise\", nbins=20,\n",
    "                   title=\"Histogram of Event Area\",\n",
    "                   labels={\"area\": \"Area (A.U.)\"})\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NANOPORE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
